{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018\n",
    "#### Due : 11/26 (TUE) 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn various classification methods with given datasets.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change train / valid / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library\n",
    "* You don't have to use all imported packages below. (some are optional). <br>\n",
    "Also, you can import additional packages in \"(Option) Other Classifiers\" part. \n",
    "* <b>*DO NOT MODIFY OTHER PARTS OF CODES EXCEPT \"Your Code Here\"*</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Additional packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own packages if you need(only in scikit-learn, numpy, pandas).\n",
    "# Your Code Here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "> 1. Load \"train.csv\". It includes all samples' features and labels.\n",
    "> 2. Training four types of classifiers(logistic regression, decision tree, random forest, support vector machine) and <b>validate</b> it in your own way. <b>(You can't get full credit if you don't conduct validation)</b>\n",
    "> 3. Optionally, if you would train your own classifier(e.g. ensembling or gradient boosting), you can evaluate your own model on the development data. <br>\n",
    "> 4. <b>You should submit your predicted results on test data with the selected classifier in your own manner.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task & dataset description\n",
    "1. 6 Features (1~6)<br>\n",
    "Feature 2, 4, 6 : Real-valued<br>\n",
    "Feature 1, 3, 5 : Categorical <br>\n",
    "\n",
    "2. Samples <br>\n",
    ">In development set : 2,000 samples <br>\n",
    ">In test set : 1,500 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load development dataset\n",
    "Load your development dataset. You should read <b>\"train.csv\"</b>. This is a classification task, and you need to preprocess your data for training your model. <br>\n",
    "> You need to use <b>1-of-K coding scheme</b>, to convert categorical features to one-hot vector. <br>\n",
    "> For example, if there are 3 categorical values, you can convert these features as [1,0,0], [0,1,0], [0,0,1] by 1-of-K coding scheme. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Plot class imbalance of train dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Print shape of dex_X, dev_y, test_X, test_y\n",
      "(1600, 6) (1600,) (400, 6) (400,)\n",
      "--------------------------------------------------\n",
      "Print shape of dev_X_one_hot, test_X_one_hot\n",
      "(1600, 23) (400, 23)\n"
     ]
    }
   ],
   "source": [
    "# For training your model, you need to convert categorical features to one-hot encoding vectors.\n",
    "# Your Code Here\n",
    "\n",
    "## Import Dataset\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "## Explore Class Imbalance\n",
    "target_count = {}\n",
    "\n",
    "for target in train.target.unique():\n",
    "    target_count[target] = len(train[train['target'] == target])\n",
    "    \n",
    "target_count_sorted = sorted(target_count.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "print(\"-----\" * 10)\n",
    "print(\"Plot class imbalance of train dataset\")\n",
    "plt.plot([x for x in range(len(target_count_sorted))], [val[1] for val in target_count_sorted])\n",
    "plt.show()\n",
    "\n",
    "## Split dev & test\n",
    "dev, test = train_test_split(train, test_size = 0.2, random_state=42)\n",
    "\n",
    "## Split X and y on dev & test sets\n",
    "dev_X, dev_y = dev.drop(columns = ['target']), dev['target']\n",
    "test_X, test_y = test.drop(columns = ['target']), test['target']\n",
    "\n",
    "print(\"-----\" * 10)\n",
    "print(\"Print shape of dex_X, dev_y, test_X, test_y\")\n",
    "print(dev_X.shape, dev_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "## One-hot encoding\n",
    "dev_X_one_hot = pd.get_dummies(dev_X)\n",
    "test_X_one_hot = pd.get_dummies(test_X)\n",
    "print(\"-----\" * 10)\n",
    "print(\"Print shape of dev_X_one_hot, test_X_one_hot\")\n",
    "print(dev_X_one_hot.shape, test_X_one_hot.shape)\n",
    "\n",
    "## Scaling\n",
    "sc = StandardScaler()\n",
    "dev_X_one_hot_std = pd.DataFrame(sc.fit_transform(dev_X_one_hot), index=dev_X_one_hot.index, columns=dev_X_one_hot.columns)\n",
    "test_X_one_hot_std = pd.DataFrame(sc.transform(test_X_one_hot), index=test_X_one_hot.index, columns=test_X_one_hot.columns)\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Train and validate your <b>logistic regression classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: [0.39674940759550553, 0.38449026518087565, 0.410730563822636, 0.38172170715035686] 0.39342298593734354\n",
      "Valid F1 Score: [0.2280561336658594, 0.23612400291462077, 0.19519072707368745, 0.23683446972433125] 0.22405133334462474\n",
      "Test F1 Score: 0.2716515459458847\n"
     ]
    }
   ],
   "source": [
    "# Training your logistic regression classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "## Define LogisticRegression Model\n",
    "### Derive model parameters using below validation codes\n",
    "### (Put parameters using greedy selection method and select best one)\n",
    "model = LogisticRegression(penalty='l2', C = 10)\n",
    "\n",
    "#####################################################################\n",
    "## Define cross validation using KFold method\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "## lists that hold error on cross validation\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "## Train & Valid Model using Cross Validation\n",
    "for train_index, valid_index in cv.split(dev_X_one_hot_std):\n",
    "    X_train, X_valid = dev_X_one_hot_std.iloc[train_index, :], dev_X_one_hot_std.iloc[valid_index, :]\n",
    "    y_train, y_valid = dev_y.iloc[train_index], dev_y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(f1_score(model.predict(X_train), y_train, average='macro'))\n",
    "    valid_error.append(f1_score(model.predict(X_valid), y_valid, average='macro'))        \n",
    "\n",
    "print(\"Train F1 Score:\", train_error, np.mean(train_error))\n",
    "print(\"Valid F1 Score:\", valid_error, np.mean(valid_error))\n",
    "\n",
    "## Report Test Error\n",
    "model.fit(dev_X_one_hot_std, dev_y)\n",
    "print(\"Test F1 Score:\", f1_score(model.predict(test_X_one_hot_std), test_y, average='macro'))\n",
    "#####################################################################\n",
    "    \n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Train and validate your <b>decision tree classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: [1.0, 1.0, 1.0, 1.0] 1.0\n",
      "Valid F1 Score: [0.28257825339047793, 0.38417923806008114, 0.34245626189928396, 0.3311194025594257] 0.3350832889773172\n",
      "Test F1 Score: 0.44948801285320505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Training your decision tree classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "## Define Decision Tree Model\n",
    "### Derive model parameters using below validation codes\n",
    "### (Put parameters using greedy selection method and select best one)\n",
    "model = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "#####################################################################\n",
    "## Define cross validation using KFold method\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "## lists that hold error on cross validation\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "## Train & Valid Model using Cross Validation\n",
    "for train_index, valid_index in cv.split(dev_X_one_hot_std):\n",
    "    X_train, X_valid = dev_X_one_hot_std.iloc[train_index, :], dev_X_one_hot_std.iloc[valid_index, :]\n",
    "    y_train, y_valid = dev_y.iloc[train_index], dev_y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(f1_score(model.predict(X_train), y_train, average='macro'))\n",
    "    valid_error.append(f1_score(model.predict(X_valid), y_valid, average='macro'))        \n",
    "\n",
    "print(\"Train F1 Score:\", train_error, np.mean(train_error))\n",
    "print(\"Valid F1 Score:\", valid_error, np.mean(valid_error))\n",
    "\n",
    "## Report Test Error\n",
    "model.fit(dev_X_one_hot_std, dev_y)\n",
    "print(\"Test F1 Score:\", f1_score(model.predict(test_X_one_hot_std), test_y, average='macro'))\n",
    "#####################################################################\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Train and validate your <b>random forest classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: [1.0, 1.0, 1.0, 1.0] 1.0\n",
      "Valid F1 Score: [0.3402672430271573, 0.35753343093210904, 0.3926946599250871, 0.328536688789115] 0.3547580056683671\n",
      "Test F1 Score: 0.5171585701310437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Training your random forest classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "## Define Random Forest Model\n",
    "### Derive model parameters using below validation codes\n",
    "### (Put parameters using greedy selection method and select best one)\n",
    "model = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "#####################################################################\n",
    "## Define cross validation using KFold method\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "## lists that hold error on cross validation\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "## Train & Valid Model using Cross Validation\n",
    "for train_index, valid_index in cv.split(dev_X_one_hot_std):\n",
    "    X_train, X_valid = dev_X_one_hot_std.iloc[train_index, :], dev_X_one_hot_std.iloc[valid_index, :]\n",
    "    y_train, y_valid = dev_y.iloc[train_index], dev_y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(f1_score(model.predict(X_train), y_train, average='macro'))\n",
    "    valid_error.append(f1_score(model.predict(X_valid), y_valid, average='macro'))        \n",
    "\n",
    "print(\"Train F1 Score:\", train_error, np.mean(train_error))\n",
    "print(\"Valid F1 Score:\", valid_error, np.mean(valid_error))\n",
    "\n",
    "## Report Test Error\n",
    "model.fit(dev_X_one_hot_std, dev_y)\n",
    "print(\"Test F1 Score:\", f1_score(model.predict(test_X_one_hot_std), test_y, average='macro'))\n",
    "#####################################################################\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Train and validate your <b>support vector machine classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: [0.8399380782786866, 0.8466594757513687, 0.8272389248576366, 0.8000104796348766] 0.8284617396306421\n",
      "Valid F1 Score: [0.37493239303594816, 0.41042156407174796, 0.37905549903420693, 0.31854284363790797] 0.3707380749449528\n",
      "Test F1 Score: 0.40380827505740763\n"
     ]
    }
   ],
   "source": [
    "# Training your support vector machine classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "## Define SVC Model\n",
    "### Derive model parameters using below validation codes\n",
    "### (Put parameters using greedy selection method and select best one)\n",
    "model = SVC(C=100, gamma=0.01, random_state=42)\n",
    "\n",
    "#####################################################################\n",
    "## Define cross validation using KFold method\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "## lists that hold error on cross validation\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "## Train & Valid Model using Cross Validation\n",
    "for train_index, valid_index in cv.split(dev_X_one_hot_std):\n",
    "    X_train, X_valid = dev_X_one_hot_std.iloc[train_index, :], dev_X_one_hot_std.iloc[valid_index, :]\n",
    "    y_train, y_valid = dev_y.iloc[train_index], dev_y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(f1_score(model.predict(X_train), y_train, average='macro'))\n",
    "    valid_error.append(f1_score(model.predict(X_valid), y_valid, average='macro'))        \n",
    "\n",
    "print(\"Train F1 Score:\", train_error, np.mean(train_error))\n",
    "print(\"Valid F1 Score:\", valid_error, np.mean(valid_error))\n",
    "\n",
    "## Report Test Error\n",
    "model.fit(dev_X_one_hot_std, dev_y)\n",
    "print(\"Test F1 Score:\", f1_score(model.predict(test_X_one_hot_std), test_y, average='macro'))\n",
    "#####################################################################\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option) Other Classifiers.\n",
    "Train and validate other classifiers by your own manner.\n",
    "> <b> If you need, you can import other models only in this cell, only in scikit-learn. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jinhe\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: [0.9974053165703362, 0.9961638167623205, 0.9953008824496936, 0.9963410149747092] 0.9963027576892648\n",
      "Valid F1 Score: [0.39766907193869305, 0.3600243976713391, 0.36054648910955794, 0.4019046311187333] 0.38003614745958086\n",
      "Test F1 Score: 0.5700837403813704\n"
     ]
    }
   ],
   "source": [
    "# If you need additional packages, import your own packages below.\n",
    "# Your Code Here\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "## Define Gradient Boosting Model\n",
    "## Derive model parameters using below validation codes\n",
    "model = GradientBoostingClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "#####################################################################\n",
    "## Define cross validation using KFold method\n",
    "## cv = ShuffleSplit(n_splits=4, test_size=0.25, random_state=42)\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "## lists that hold error on cross validation\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "## Train & Valid Model using Cross Validation\n",
    "for train_index, valid_index in cv.split(dev_X_one_hot_std):\n",
    "    X_train, X_valid = dev_X_one_hot_std.iloc[train_index, :], dev_X_one_hot_std.iloc[valid_index, :]\n",
    "    y_train, y_valid = dev_y.iloc[train_index], dev_y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(f1_score(model.predict(X_train), y_train, average='macro'))\n",
    "    valid_error.append(f1_score(model.predict(X_valid), y_valid, average='macro'))        \n",
    "\n",
    "print(\"Train F1 Score:\", train_error, np.mean(train_error))\n",
    "print(\"Valid F1 Score:\", valid_error, np.mean(valid_error))\n",
    "\n",
    "## Report Test Error\n",
    "model.fit(dev_X_one_hot_std, dev_y)\n",
    "print(\"Test F1 Score:\", f1_score(model.predict(test_X_one_hot_std), test_y, average='macro'))\n",
    "#####################################################################\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your prediction on the test data.\n",
    "\n",
    "* Select your model and explain it briefly.\n",
    "* You should read <b>\"test.csv\"</b>.\n",
    "* Prerdict your model in array form.\n",
    "* Prediction example <br>\n",
    "[2, 6, 14, 8, $\\cdots$]\n",
    "* We will rank your result by <b>F1 metric(with 'macro' option)</b>.\n",
    "* <b> If you don't submit prediction file or submit it in wrong format, you can't get the point for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전 Test data에 대한 final model로 <b>Gradient Boosting Classifier</b>을 선택하였습니다.\n",
    "\n",
    "Gradient Boosting은 Ensemble 기법 중 Boosting을 고도화 한 모델입니다.\n",
    "\n",
    "Gradient Boosting의 Hyper-parameter을 설정할 때는 적용해볼법한 parameter을 리스트화 한 다음,<br>greedy selection 으로 f1-score가 가장 높은 파라미터를 선택하였습니다.\n",
    "\n",
    "Gradient Boosting을 사용한 이유는 위에서 F1 score를 metric으로 계산하였을 때,\n",
    "1. Validation Set에 대한 F1 Score가 가장 높았기 때문이고,\n",
    "2. Report 목적으로 생성한 Test dataset에 대해서도 F1 score가 가장 높았기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Print shape of train_X_one_hot, train_y, test_X_one_hot\n",
      "(2000, 23) (2000,) (1500, 23)\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset.\n",
    "# Your Code Here\n",
    "\n",
    "## Import train & test Dataset\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test_X = pd.read_csv('./data/test.csv')\n",
    "\n",
    "## Split X and y on train dataset\n",
    "train_X, train_y = train.drop(columns = ['target']), train['target']\n",
    "\n",
    "## One-hot encoding\n",
    "train_X_one_hot = pd.get_dummies(train_X)\n",
    "test_X_one_hot = pd.get_dummies(test_X)\n",
    "print(\"-----\" * 10)\n",
    "print(\"Print shape of train_X_one_hot, train_y, test_X_one_hot\")\n",
    "print(train_X_one_hot.shape, train_y.shape, test_X_one_hot.shape)\n",
    "\n",
    "## Scaling\n",
    "sc = StandardScaler()\n",
    "train_X_one_hot_std = pd.DataFrame(sc.fit_transform(train_X_one_hot), index=train_X_one_hot.index, columns=train_X_one_hot.columns)\n",
    "test_X_one_hot_std = pd.DataFrame(sc.transform(test_X_one_hot), index=test_X_one_hot.index, columns=test_X_one_hot.columns)\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target class\n",
    "# Make variable \"my_answer\", type of array, and fill this array with your class predictions.\n",
    "# Modify file name into your student number and your name.\n",
    "# Your Code Here\n",
    "\n",
    "## Select Gradient Boosting Classifier (Optional Classifier)\n",
    "model = GradientBoostingClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "## Fit model and fill my_answer\n",
    "model.fit(train_X_one_hot_std, train_y)\n",
    "my_answer = model.predict(test_X_one_hot_std)\n",
    "\n",
    "file_name = \"HW2_2016320198_백진헌.csv\"\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for saving predicted answers. DO NOT MODIFY.\n",
    "pd.Series(my_answer).to_csv(\"./data/\" + file_name, header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
